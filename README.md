# ğŸŒŒ Omni-Retail: Enterprise Multi-Agent Intelligence

[![Live Demo](https://omni-retail-1.onrender.com/)](YOUR_RENDER_APP_URL_HERE)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/)
[![Next.js](https://img.shields.io/badge/Next.js-15+-black.svg)](https://nextjs.org/)

Omni-Retail is a production-grade, multi-agent AI ecosystem designed to unify disparate enterprise data sourcesâ€”**Retail, Logistics, FinTech, and Customer Support**â€”into a single, conversational interface. Powered by **Groq Llama 3.3 70B**, it provides split-second reasoning across production-scale synthetic data with a **voice-first** user experience.

---

## ğŸ—ï¸ System Architecture

The project utilizes a **Modular Agentic Reasoning** architecture, ensuring absolute data isolation and high-precision retrieval.

### ğŸ§© The Multi-Agent Logic Core
The system is orchestrated by a central "Brain" (`orchestrator_groq.py`) that manages specialized sub-agents:

1.  **The Planner**: Analyzes user intent and determines the optimal sequence of database lookups across all platforms.
2.  **Specialized Sub-Agents**:
    *   **ShopCore Agent** (`src/subagents/shopcore.py`): Manages user profiles, product catalogs, and order history.
    *   **ShipStream Agent** (`src/subagents/shipstream.py`): Handles global tracking, warehouse logistics, and shipping status.
    *   **PayGuard Agent** (`src/subagents/payguard.py`): Oversees virtual wallets, transactions, and payment security.
    *   **CareDesk Agent** (`src/subagents/caredesk.py`): Manages support tickets, agent messages, and satisfaction surveys.
3.  **Identity Resolver**: Proactively identifies anonymous users (e.g., "Where is my order?") by cross-referencing recent transactions.
4.  **Synthesis Engine**: Merges raw data into professional, HTML-formatted dashboard responses with automated Text-to-Speech.

### ğŸ—„ï¸ Four-Platform Database Ecosystem
We maintain 4 separate SQLite databases to simulate a real-world enterprise environment where data is siloed:

| Database | Focus | Key Tables | Agent |
|:---------|:------|:-----------|:------|
| **ShopCore** | Retail Operations | Users, Products, Orders | ShopCore Agent |
| **ShipStream** | Logistics & Tracking | Shipments, Warehouses, TrackingEvents | ShipStream Agent |
| **PayGuard** | Financial Transactions | Wallets, Transactions, PaymentMethods | PayGuard Agent |
| **CareDesk** | Customer Support | Tickets, TicketMessages, Surveys | CareDesk Agent |

---

## âœ¨ Features

- **ğŸš€ Ultra-Low Latency**: Sub-second inference powered by Groq's Llama-3.3-70B model.
- **ğŸ™ï¸ Voice-First Interface**: 
  - Speak your queries naturally using the Web Speech API
  - Automatic speech-to-text conversion
  - AI reads responses back to you with Text-to-Speech
  - Hands-free operation with auto-submit
- **ğŸ“Š Adaptive Dashboards**: Responses formatted in rich HTML with automatic bolding of IDs, statuses, and currency.
- **ğŸ›¡ï¸ Secure SQL Generation**: Queries generated within strict database sandboxes, preventing cross-database hallucinations.
- **ğŸ­ Anonymous Query Handling**: Identifies users even when they don't provide their name (e.g., "I ordered a Gaming Monitor").
- **ğŸ“ˆ Production-Scale Data**: Includes automated generator creating 500+ users, 2000+ orders, and 500+ support tickets.
- **ğŸ”„ Model Failover**: Automatic fallback to Llama-3.1-8B in case of Groq rate limits.
- **ğŸ¨ Premium UI**: Dark mode, glassmorphism effects, smooth animations with Framer Motion.

---

## ğŸ› ï¸ Tech Stack

### Frontend
- **Framework**: [Next.js 15+](https://nextjs.org/) with React 19
- **Styling**: [Tailwind CSS 4](https://tailwindcss.com/)
- **Animations**: [Framer Motion](https://www.framer.com/motion/)
- **Icons**: [Lucide React](https://lucide.dev/)
- **Voice**: Web Speech API (Native Browser Support)
- **License**: MIT

### Backend
- **Language**: [Python 3.10+](https://www.python.org/)
- **API Framework**: [FastAPI](https://fastapi.tiangolo.com/)
- **Server**: [Uvicorn](https://www.uvicorn.org/)
- **LLM SDK**: [Groq Python](https://github.com/groq/groq-python)
- **Database**: SQLite3 (with 4 separate databases)
- **Data Generation**: [Faker](https://faker.readthedocs.io/)
- **License**: MIT

### Key Dependencies
```
Backend:
- fastapi
- pydantic
- uvicorn
- groq
- python-dotenv
- faker

Frontend:
- next@16.1.3
- react@19.2.3
- framer-motion@12.26.2
- tailwindcss@4
- lucide-react@0.562.0
```

---

## ğŸš€ Getting Started

### 1. Prerequisites
- **Python 3.10+** installed
- **Node.js 18+** installed
- A **[Groq API Key](https://console.groq.com/)** (free tier available)

### 2. Installation

```bash
# Clone the repository
git clone https://github.com/your-username/omni-retail.git
cd omni-retail

# Install Python backend dependencies
pip install -r requirements.txt

# Install Frontend dependencies
npm install
```

### 3. Environment Setup

Create a `.env` file in the root directory:
```env
GROQ_API_KEY=your_groq_api_key_here
```

### 4. Database Initialization

Generate the production-scale synthetic data (500 users, 2000 orders):
```bash
python setup_dbs.py
```

This creates 4 SQLite databases in the `data/` folder:
- `DB_ShopCore.db`
- `DB_ShipStream.db`
- `DB_PayGuard.db`
- `DB_CareDesk.db`

---

## ğŸƒ Running the Application

### Option A: One-Click Launch (Windows)
```powershell
.\run_all.bat
```
This automatically:
1. Cleans up any existing sessions on port 8000
2. Starts the FastAPI backend
3. Starts the Next.js frontend

### Option B: Manual Start

**Terminal 1 - Backend:**
```bash
python src/server.py
```

**Terminal 2 - Frontend:**
```bash
npm run dev
```

### Access the Application
- **Frontend**: http://localhost:3000
- **Backend API**: http://localhost:8000
- **API Docs**: http://localhost:8000/docs

---

## ğŸ’¬ Sample Queries

Test the full power of the multi-agent system with these queries:

### Anonymous Identity Recovery
> *"I ordered a **Gaming Monitor** recently. Can you check my **shipping status**, my current **wallet balance**, and see if the **support ticket** I opened has been resolved?"*

**Triggers**: ShopCore â†’ ShipStream â†’ PayGuard â†’ CareDesk

### Full 360Â° Status Check
> *"I am **Alice Johnson**. Give me a complete update on my latest order: the **product name**, which **warehouse** it's at, if my **payment** was successful, and the latest **support message**."*

**Triggers**: All 4 agents in sequence

### Financial & Feedback Audit
> *"Check everything for **Chad Baldwin**. What did he last buy, is it delivered, what is his **account balance**, and did he leave a **satisfaction survey**?"*

**Triggers**: ShopCore â†’ ShipStream â†’ PayGuard â†’ CareDesk (with survey lookup)

### Logistics Deep-Dive
> *"Check **order #1200**. Tell me the **tracking number**, which **warehouse manager** is responsible, my current **balance**, and the **status** of my last support inquiry."*

**Triggers**: ShopCore â†’ ShipStream â†’ PayGuard â†’ CareDesk

---

## ğŸŒ Deployment

### Local Development
This project works perfectly for local development using the `run_all.bat` script or manual commands.

### Production Deployment (Render.com) â­ Recommended
This project is optimized for deployment on **[Render.com](https://render.com)**, which supports:
- âœ… **SQLite databases** with persistent disk storage
- âœ… **Python and Node.js** applications
- âœ… **Free tier** available
- âœ… **Auto-deploy** on git push
- âœ… **Environment variables** management

**See [RENDER_DEPLOYMENT.md](./RENDER_DEPLOYMENT.md) for complete step-by-step deployment instructions.**

### Alternative Platforms
- **Railway.app**: Supports SQLite with persistent volumes
- **DigitalOcean App Platform**: Supports persistent storage
- **Fly.io**: Supports persistent volumes

**Note**: Vercel and other serverless platforms are **not compatible** due to read-only filesystems (SQLite requires write access).

---

## ğŸ“ Project Structure

```
omni-retail/
â”œâ”€â”€ src/                          # Python Backend
â”‚   â”œâ”€â”€ orchestrator_groq.py     # Main AI orchestrator
â”‚   â”œâ”€â”€ server.py                # FastAPI server
â”‚   â”œâ”€â”€ utils.py                 # Database utilities
â”‚   â””â”€â”€ subagents/               # Specialized agents
â”‚       â”œâ”€â”€ shopcore.py          # Retail agent
â”‚       â”œâ”€â”€ shipstream.py        # Logistics agent
â”‚       â”œâ”€â”€ payguard.py          # FinTech agent
â”‚       â””â”€â”€ caredesk.py          # Support agent
â”œâ”€â”€ app/                         # Next.js App Router
â”‚   â”œâ”€â”€ page.tsx                 # Main page
â”‚   â”œâ”€â”€ layout.tsx               # Root layout
â”‚   â””â”€â”€ globals.css              # Global styles
â”œâ”€â”€ components/                  # React Components
â”‚   â””â”€â”€ OmniAgentUI.tsx         # Main chat interface
â”œâ”€â”€ data/                        # SQLite Databases
â”‚   â”œâ”€â”€ DB_ShopCore.db
â”‚   â”œâ”€â”€ DB_ShipStream.db
â”‚   â”œâ”€â”€ DB_PayGuard.db
â”‚   â””â”€â”€ DB_CareDesk.db
â”œâ”€â”€ public/                      # Static assets
â”œâ”€â”€ setup_dbs.py                 # Database generator
â”œâ”€â”€ demo.py                      # CLI demo script
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ package.json                 # Node.js dependencies
â”œâ”€â”€ README.md                    # This file
â”œâ”€â”€ RENDER_DEPLOYMENT.md         # Deployment guide
â””â”€â”€ LICENSE                      # MIT License
```

---

## ğŸ“œ License & Acknowledgments

### License
Distributed under the **MIT License**. See [LICENSE](./LICENSE) for more information.

### Acknowledgments
- **[Groq](https://groq.com)** - For providing the world's fastest LLM inference engine
- **[Meta AI](https://ai.meta.com/)** - For the Llama 3.3 70B and Llama 3.1 8B models
- **[Vercel](https://vercel.com)** - For Next.js and frontend infrastructure inspiration
- **[FastAPI](https://fastapi.tiangolo.com/)** - For the high-performance Python backend framework
- **[Faker](https://faker.readthedocs.io/)** - For realistic synthetic data generation

### Repository Information
- **Author**: Kshitij Sharma
- **Year**: 2026
